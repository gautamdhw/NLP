{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>ASSIGNMENT 5</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KZ-R4GUskerC"
   },
   "source": [
    "# Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ZSwdBRpkerE"
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JuYqCv4KkerE"
   },
   "source": [
    "Another popular text analysis technique is called topic modeling. The ultimate goal of topic modeling is to find various topics that are present in your corpus. Each document in the corpus will be made up of at least one topic, if not multiple topics.\n",
    "\n",
    "In this notebook, we will be covering the steps on how to do **Latent Dirichlet Allocation (LDA)**, which is one of many topic modeling techniques. It was specifically designed for text data.\n",
    "\n",
    "To use a topic modeling technique, you need to provide (1) a document-term matrix and (2) the number of topics you would like the algorithm to pick up.\n",
    "\n",
    "Once the topic modeling technique is applied, your job as a human is to interpret the results and see if the mix of words in each topic make sense. If they don't make sense, you can try changing up the number of topics, the terms in the document-term matrix, model parameters, or even try a different model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nDP7AbjpkerF"
   },
   "source": [
    "## Topic Modeling - Attempt #1 (All Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "-20LdzmqkerF"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abandons</th>\n",
       "      <th>abide</th>\n",
       "      <th>abidjan</th>\n",
       "      <th>abilities</th>\n",
       "      <th>able</th>\n",
       "      <th>abruptly</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>absorbs</th>\n",
       "      <th>abuse</th>\n",
       "      <th>...</th>\n",
       "      <th>zap</th>\n",
       "      <th>zapper</th>\n",
       "      <th>zeph</th>\n",
       "      <th>zephs</th>\n",
       "      <th>zero</th>\n",
       "      <th>zilch</th>\n",
       "      <th>zocalo</th>\n",
       "      <th>zone</th>\n",
       "      <th>zones</th>\n",
       "      <th>zoom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>all-about-my-mother-1999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>babygirl</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>den-of-thieves-2-pantera</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moana-2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sonic-the-hedgehog-3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>star-trek-section-31</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows Ã— 5300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          abandoned  abandons  abide  abidjan  abilities  \\\n",
       "all-about-my-mother-1999          0         0      0        0          0   \n",
       "babygirl                          0         0      0        0          0   \n",
       "den-of-thieves-2-pantera          0         0      0        1          0   \n",
       "moana-2                           0         0      0        0          0   \n",
       "sonic-the-hedgehog-3              1         3      1        0          1   \n",
       "star-trek-section-31              0         0      0        0          0   \n",
       "\n",
       "                          able  abruptly  absolutely  absorbs  abuse  ...  \\\n",
       "all-about-my-mother-1999     2         0           0        0      0  ...   \n",
       "babygirl                     1         0           1        0      0  ...   \n",
       "den-of-thieves-2-pantera     1         0           0        0      0  ...   \n",
       "moana-2                      2         0           0        0      0  ...   \n",
       "sonic-the-hedgehog-3         1         1           4        1      1  ...   \n",
       "star-trek-section-31         1         0           2        0      0  ...   \n",
       "\n",
       "                          zap  zapper  zeph  zephs  zero  zilch  zocalo  zone  \\\n",
       "all-about-my-mother-1999    0       0     0      0     0      0       0     0   \n",
       "babygirl                    0       0     0      0     0      0       0     0   \n",
       "den-of-thieves-2-pantera    0       0     0      0     1      0       1     0   \n",
       "moana-2                     0       0     0      0     0      0       0     0   \n",
       "sonic-the-hedgehog-3        1       1     0      0     1      1       0     1   \n",
       "star-trek-section-31        0       0    37      9     0      0       0     0   \n",
       "\n",
       "                          zones  zoom  \n",
       "all-about-my-mother-1999      0     0  \n",
       "babygirl                      0     0  \n",
       "den-of-thieves-2-pantera      2     1  \n",
       "moana-2                       0     0  \n",
       "sonic-the-hedgehog-3          0     0  \n",
       "star-trek-section-31          0     0  \n",
       "\n",
       "[6 rows x 5300 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's read in our document-term matrix\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "data = pd.read_pickle('dtm_stop.pkl')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "NwrK0iL_kerF"
   },
   "outputs": [],
   "source": [
    "# Import the necessary modules for LDA with gensim\n",
    "# Terminal / Anaconda Navigator: conda install -c conda-forge gensim\n",
    "from gensim import matutils, models\n",
    "import scipy.sparse\n",
    "\n",
    "# import logging\n",
    "# logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "y3aivrUwkerG"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all-about-my-mother-1999</th>\n",
       "      <th>babygirl</th>\n",
       "      <th>den-of-thieves-2-pantera</th>\n",
       "      <th>moana-2</th>\n",
       "      <th>sonic-the-hedgehog-3</th>\n",
       "      <th>star-trek-section-31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>abandoned</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abandons</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abide</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abidjan</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abilities</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           all-about-my-mother-1999  babygirl  den-of-thieves-2-pantera  \\\n",
       "abandoned                         0         0                         0   \n",
       "abandons                          0         0                         0   \n",
       "abide                             0         0                         0   \n",
       "abidjan                           0         0                         1   \n",
       "abilities                         0         0                         0   \n",
       "\n",
       "           moana-2  sonic-the-hedgehog-3  star-trek-section-31  \n",
       "abandoned        0                     1                     0  \n",
       "abandons         0                     3                     0  \n",
       "abide            0                     1                     0  \n",
       "abidjan          0                     0                     0  \n",
       "abilities        0                     1                     0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One of the required inputs is a term-document matrix\n",
    "#tdm->term document matrix\n",
    "tdm = data.transpose()\n",
    "tdm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "-OH1R7APkerG"
   },
   "outputs": [],
   "source": [
    "# We're going to put the term-document matrix into a new gensim format, from df --> sparse matrix --> gensim corpus\n",
    "sparse_counts = scipy.sparse.csr_matrix(tdm) #converts tdm to compressed sparse row matrix\n",
    "corpus = matutils.Sparse2Corpus(sparse_counts) #converts sparse matrix to Gensim corpus\n",
    "#gensim requires its own format hence we do this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "sJHCrNCHkerG"
   },
   "outputs": [],
   "source": [
    "# Gensim also requires dictionary of the all terms and their respective location in the term-document matrix\n",
    "cv = pickle.load(open(\"cv_stop.pkl\", \"rb\"))\n",
    "id2word = dict((v, k) for k, v in cv.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I6wGZ84MkerH"
   },
   "source": [
    "Now that we have the corpus (term-document matrix) and id2word (dictionary of location: term), we need to specify two other parameters - the number of topics and the number of passes. Let's start the number of topics at 1, see if the results make sense, and increase the number from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.006*\"okay\" + 0.006*\"got\" + 0.006*\"yeah\" + 0.006*\"oh\" + 0.006*\"music\" + 0.005*\"hey\" + 0.005*\"want\" + 0.004*\"thats\" + 0.004*\"grunts\" + 0.004*\"na\"')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=1, passes=10)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KEY FINDINGS:\n",
    "- The top words that define this topic : \"okay\",\"got\",\"yeah\",\"oh\"\n",
    "- all these has the highest weight (0.006) â€” itâ€™s the most dominant word in this topic.\n",
    "- The others have slightly lower weights but still contribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "1Sd-K-sfkerH"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.010*\"okay\" + 0.010*\"hey\" + 0.010*\"music\" + 0.009*\"yeah\" + 0.009*\"english\" + 0.008*\"nick\" + 0.007*\"fuck\" + 0.007*\"good\" + 0.007*\"donnie\" + 0.007*\"oh\"'),\n",
       " (1,\n",
       "  '0.007*\"got\" + 0.006*\"moana\" + 0.005*\"oh\" + 0.005*\"grunts\" + 0.005*\"look\" + 0.004*\"na\" + 0.004*\"thats\" + 0.004*\"okay\" + 0.004*\"sonic\" + 0.004*\"way\"')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now that we have the corpus (term-document matrix) and id2word (dictionary of location: term),\n",
    "# we need to specify two other parameters as well - the number of topics and the number of passes\n",
    "lda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=2, passes=20)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Hx0ukBHQkerH"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.010*\"want\" + 0.008*\"okay\" + 0.007*\"yeah\" + 0.007*\"yes\" + 0.007*\"oh\" + 0.006*\"look\" + 0.006*\"think\" + 0.006*\"got\" + 0.006*\"hey\" + 0.006*\"ill\"'),\n",
       " (1,\n",
       "  '0.008*\"sonic\" + 0.006*\"okay\" + 0.006*\"oh\" + 0.005*\"georgiou\" + 0.005*\"yeah\" + 0.005*\"quasi\" + 0.004*\"thats\" + 0.004*\"got\" + 0.004*\"alok\" + 0.004*\"shadow\"'),\n",
       " (2,\n",
       "  '0.012*\"music\" + 0.011*\"moana\" + 0.009*\"english\" + 0.009*\"playing\" + 0.009*\"nick\" + 0.008*\"grunts\" + 0.007*\"got\" + 0.007*\"donnie\" + 0.007*\"hey\" + 0.007*\"maui\"')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LDA for num_topics = 3\n",
    "lda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=3, passes=30)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "APhpX97WkerH"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.000*\"okay\" + 0.000*\"thats\" + 0.000*\"want\" + 0.000*\"yeah\" + 0.000*\"hey\" + 0.000*\"music\" + 0.000*\"grunts\" + 0.000*\"got\" + 0.000*\"oh\" + 0.000*\"moana\"'),\n",
       " (1,\n",
       "  '0.021*\"moana\" + 0.014*\"maui\" + 0.010*\"gasps\" + 0.010*\"grunts\" + 0.009*\"music\" + 0.008*\"got\" + 0.008*\"na\" + 0.008*\"playing\" + 0.007*\"moni\" + 0.006*\"way\"'),\n",
       " (2,\n",
       "  '0.010*\"english\" + 0.009*\"nick\" + 0.009*\"music\" + 0.008*\"donnie\" + 0.007*\"fuck\" + 0.007*\"yeah\" + 0.007*\"french\" + 0.007*\"okay\" + 0.006*\"hey\" + 0.006*\"georgiou\"'),\n",
       " (3,\n",
       "  '0.008*\"okay\" + 0.008*\"want\" + 0.007*\"oh\" + 0.007*\"yeah\" + 0.006*\"got\" + 0.006*\"look\" + 0.006*\"sonic\" + 0.006*\"yes\" + 0.006*\"thats\" + 0.005*\"hey\"')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LDA for num_topics = 4\n",
    "lda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=4, passes=40)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ie-kilqbkerI"
   },
   "source": [
    "These topics aren't looking too great. We've tried modifying our parameters. Let's try modifying our terms list as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AxWFitW7kerI"
   },
   "source": [
    "## Topic Modeling - Attempt #2 (Nouns Only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QbWgNJ4pkerI"
   },
   "source": [
    "One popular trick is to look only at terms that are from one part of speech (only nouns, only adjectives, etc.). Check out the UPenn tag set: https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "hx1iAfaLkerI"
   },
   "outputs": [],
   "source": [
    "# Let's create a function to pull out nouns from a string of text\n",
    "from nltk import word_tokenize, pos_tag\n",
    "\n",
    "def nouns(text):\n",
    "    '''Given a string of text, tokenize the text and pull out only the nouns.'''\n",
    "    is_noun = lambda pos: pos[:2] == 'NN'\n",
    "    tokenized = word_tokenize(text)\n",
    "    all_nouns = [word for (word, pos) in pos_tag(tokenized) if is_noun(pos)]\n",
    "    return ' '.join(all_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "oJJ4nTM4kerI"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>all-about-my-mother-1999</th>\n",
       "      <td>mother transcript scraps loft skip content sea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>babygirl</th>\n",
       "      <td>babygirl transcript scraps loft skip content s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>den-of-thieves-2-pantera</th>\n",
       "      <td>den thieves pantera transcript scraps loft ski...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moana-2</th>\n",
       "      <td>moana transcript scraps loft skip content sear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sonic-the-hedgehog-3</th>\n",
       "      <td>sonic hedgehog transcript scraps loft skip con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>star-trek-section-31</th>\n",
       "      <td>star trek section transcript scraps loft skip ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 transcript\n",
       "all-about-my-mother-1999  mother transcript scraps loft skip content sea...\n",
       "babygirl                  babygirl transcript scraps loft skip content s...\n",
       "den-of-thieves-2-pantera  den thieves pantera transcript scraps loft ski...\n",
       "moana-2                   moana transcript scraps loft skip content sear...\n",
       "sonic-the-hedgehog-3      sonic hedgehog transcript scraps loft skip con...\n",
       "star-trek-section-31      star trek section transcript scraps loft skip ..."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the cleaned data, before the CountVectorizer step\n",
    "data_clean = pd.read_pickle('data_clean.pkl')\n",
    "data_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "pG2F7S4MkerJ"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>all-about-my-mother-1999</th>\n",
       "      <td>mother transcript scraps content search movies...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>babygirl</th>\n",
       "      <td>babygirl transcript scraps content search movi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>den-of-thieves-2-pantera</th>\n",
       "      <td>thieves transcript scraps content search movie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moana-2</th>\n",
       "      <td>moana scraps content search movies movie movie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sonic-the-hedgehog-3</th>\n",
       "      <td>hedgehog transcript scraps content search movi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>star-trek-section-31</th>\n",
       "      <td>star trek section transcript scraps content se...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 transcript\n",
       "all-about-my-mother-1999  mother transcript scraps content search movies...\n",
       "babygirl                  babygirl transcript scraps content search movi...\n",
       "den-of-thieves-2-pantera  thieves transcript scraps content search movie...\n",
       "moana-2                   moana scraps content search movies movie movie...\n",
       "sonic-the-hedgehog-3      hedgehog transcript scraps content search movi...\n",
       "star-trek-section-31      star trek section transcript scraps content se..."
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the nouns function to the transcripts to filter only on nouns\n",
    "data_nouns = pd.DataFrame(data_clean.transcript.apply(nouns))\n",
    "data_nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "PSXkcNqJkerJ"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abandons</th>\n",
       "      <th>abidjan</th>\n",
       "      <th>abilities</th>\n",
       "      <th>absorbs</th>\n",
       "      <th>abuse</th>\n",
       "      <th>access</th>\n",
       "      <th>accident</th>\n",
       "      <th>account</th>\n",
       "      <th>accountability</th>\n",
       "      <th>accounts</th>\n",
       "      <th>...</th>\n",
       "      <th>youngwell</th>\n",
       "      <th>youve</th>\n",
       "      <th>zamba</th>\n",
       "      <th>zap</th>\n",
       "      <th>zapper</th>\n",
       "      <th>zeph</th>\n",
       "      <th>zephs</th>\n",
       "      <th>zone</th>\n",
       "      <th>zones</th>\n",
       "      <th>zoom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>all-about-my-mother-1999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>babygirl</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>den-of-thieves-2-pantera</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moana-2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sonic-the-hedgehog-3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>star-trek-section-31</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows Ã— 3092 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          abandons  abidjan  abilities  absorbs  abuse  \\\n",
       "all-about-my-mother-1999         0        0          0        0      0   \n",
       "babygirl                         0        0          0        0      0   \n",
       "den-of-thieves-2-pantera         0        1          0        0      0   \n",
       "moana-2                          0        0          0        0      0   \n",
       "sonic-the-hedgehog-3             3        0          1        1      1   \n",
       "star-trek-section-31             0        0          0        0      0   \n",
       "\n",
       "                          access  accident  account  accountability  accounts  \\\n",
       "all-about-my-mother-1999       0         2        0               0         0   \n",
       "babygirl                       0         0        0               1         0   \n",
       "den-of-thieves-2-pantera       4         0        1               0         0   \n",
       "moana-2                        0         0        0               0         1   \n",
       "sonic-the-hedgehog-3           1         1        0               0         1   \n",
       "star-trek-section-31           0         0        0               0         0   \n",
       "\n",
       "                          ...  youngwell  youve  zamba  zap  zapper  zeph  \\\n",
       "all-about-my-mother-1999  ...          1      9      0    0       0     0   \n",
       "babygirl                  ...          0      0      0    0       0     0   \n",
       "den-of-thieves-2-pantera  ...          0      4      3    0       0     0   \n",
       "moana-2                   ...          0      5      0    0       0     0   \n",
       "sonic-the-hedgehog-3      ...          0      5      0    1       1     0   \n",
       "star-trek-section-31      ...          0      0      0    0       0    26   \n",
       "\n",
       "                          zephs  zone  zones  zoom  \n",
       "all-about-my-mother-1999      0     0      0     0  \n",
       "babygirl                      0     0      0     0  \n",
       "den-of-thieves-2-pantera      0     0      2     1  \n",
       "moana-2                       0     0      0     0  \n",
       "sonic-the-hedgehog-3          0     1      0     0  \n",
       "star-trek-section-31          7     0      0     0  \n",
       "\n",
       "[6 rows x 3092 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new document-term matrix using only nouns\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Re-add the additional stop words since we are recreating the document-term matrix\n",
    "add_stop_words = ['like', 'im', 'know', 'just', 'dont', 'thats', 'right', 'people',\n",
    "                  'youre', 'got', 'gonna', 'time', 'think', 'yeah', 'said']\n",
    "stop_words = text.ENGLISH_STOP_WORDS.union(add_stop_words)\n",
    "\n",
    "# Recreate a document-term matrix with only nouns\n",
    "cvn = CountVectorizer(stop_words=list(stop_words))\n",
    "data_cvn = cvn.fit_transform(data_nouns.transcript)\n",
    "data_dtmn = pd.DataFrame(data_cvn.toarray(), columns=cvn.get_feature_names_out())\n",
    "data_dtmn.index = data_nouns.index\n",
    "data_dtmn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "yTX-RimgkerJ"
   },
   "outputs": [],
   "source": [
    "# Create the gensim corpus\n",
    "corpusn = matutils.Sparse2Corpus(scipy.sparse.csr_matrix(data_dtmn.transpose()))\n",
    "\n",
    "# Create the vocabulary dictionary\n",
    "id2wordn = dict((v, k) for k, v in cvn.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.012*\"music\" + 0.009*\"grunts\" + 0.007*\"way\" + 0.006*\"hey\" + 0.006*\"gon\" + 0.005*\"moana\" + 0.005*\"okay\" + 0.005*\"look\" + 0.005*\"chuckles\" + 0.004*\"sighs\"')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's start with 1 topic\n",
    "ldan = models.LdaModel(corpus=corpusn, num_topics=1, id2word=id2wordn, passes=10)\n",
    "ldan.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "0h-rOi6ykerJ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.007*\"look\" + 0.006*\"okay\" + 0.006*\"way\" + 0.005*\"hey\" + 0.005*\"chatter\" + 0.005*\"man\" + 0.005*\"yes\" + 0.005*\"music\" + 0.005*\"woman\" + 0.005*\"shes\"'),\n",
       " (1,\n",
       "  '0.018*\"music\" + 0.014*\"grunts\" + 0.010*\"moana\" + 0.008*\"way\" + 0.008*\"chuckles\" + 0.007*\"gon\" + 0.006*\"hey\" + 0.005*\"donnie\" + 0.005*\"sighs\" + 0.005*\"maui\"')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's start with 2 topics\n",
    "ldan = models.LdaModel(corpus=corpusn, num_topics=2, id2word=id2wordn, passes=10)\n",
    "ldan.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "3MpUNmK7kerJ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.016*\"moana\" + 0.015*\"grunts\" + 0.012*\"music\" + 0.010*\"way\" + 0.009*\"chuckles\" + 0.009*\"gon\" + 0.008*\"maui\" + 0.007*\"georgiou\" + 0.007*\"gasps\" + 0.006*\"garrett\"'),\n",
       " (1,\n",
       "  '0.008*\"shes\" + 0.008*\"look\" + 0.007*\"son\" + 0.006*\"yes\" + 0.006*\"didnt\" + 0.006*\"thank\" + 0.006*\"years\" + 0.006*\"night\" + 0.006*\"huma\" + 0.005*\"work\"'),\n",
       " (2,\n",
       "  '0.016*\"music\" + 0.010*\"hey\" + 0.009*\"okay\" + 0.008*\"grunts\" + 0.008*\"chatter\" + 0.007*\"man\" + 0.006*\"gon\" + 0.006*\"way\" + 0.006*\"donnie\" + 0.006*\"sighs\"')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try topics = 3\n",
    "ldan = models.LdaModel(corpus=corpusn, num_topics=3, id2word=id2wordn, passes=10)\n",
    "ldan.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "q1F9Fv0ykerJ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.012*\"georgiou\" + 0.010*\"garrett\" + 0.010*\"quasi\" + 0.010*\"zeph\" + 0.008*\"alok\" + 0.008*\"grunts\" + 0.007*\"fuzz\" + 0.007*\"ship\" + 0.006*\"gon\" + 0.005*\"chuckles\"'),\n",
       " (1,\n",
       "  '0.023*\"music\" + 0.013*\"hey\" + 0.012*\"chatter\" + 0.010*\"man\" + 0.009*\"donnie\" + 0.009*\"grunts\" + 0.009*\"okay\" + 0.008*\"sighs\" + 0.007*\"fuck\" + 0.007*\"woman\"'),\n",
       " (2,\n",
       "  '0.028*\"moana\" + 0.020*\"grunts\" + 0.019*\"music\" + 0.014*\"maui\" + 0.013*\"way\" + 0.011*\"chuckles\" + 0.010*\"gasps\" + 0.010*\"gon\" + 0.009*\"moni\" + 0.008*\"island\"'),\n",
       " (3,\n",
       "  '0.008*\"look\" + 0.007*\"way\" + 0.007*\"shadow\" + 0.006*\"years\" + 0.006*\"yes\" + 0.006*\"shes\" + 0.006*\"knuckles\" + 0.005*\"day\" + 0.005*\"family\" + 0.005*\"okay\"')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try 4 topics\n",
    "ldan = models.LdaModel(corpus=corpusn, num_topics=4, id2word=id2wordn, passes=10)\n",
    "ldan.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6qSpXm0dkerJ"
   },
   "source": [
    "## Topic Modeling - Attempt #3 (Nouns and Adjectives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "Um1c3KXskerJ"
   },
   "outputs": [],
   "source": [
    "# Let's create a function to pull out nouns from a string of text\n",
    "def nouns_adj(text):\n",
    "    '''Given a string of text, tokenize the text and pull out only the nouns and adjectives.'''\n",
    "    is_noun_adj = lambda pos: pos[:2] == 'NN' or pos[:2] == 'JJ'\n",
    "    tokenized = word_tokenize(text)\n",
    "    nouns_adj = [word for (word, pos) in pos_tag(tokenized) if is_noun_adj(pos)]\n",
    "    return ' '.join(nouns_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "8nEdN-eDkerK"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>all-about-my-mother-1999</th>\n",
       "      <td>mother transcript scraps loft skip content sea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>babygirl</th>\n",
       "      <td>babygirl transcript scraps loft skip content s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>den-of-thieves-2-pantera</th>\n",
       "      <td>den thieves transcript scraps loft skip conten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moana-2</th>\n",
       "      <td>moana scraps loft skip content search movies m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sonic-the-hedgehog-3</th>\n",
       "      <td>sonic hedgehog transcript scraps loft skip con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>star-trek-section-31</th>\n",
       "      <td>star trek section transcript scraps loft skip ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 transcript\n",
       "all-about-my-mother-1999  mother transcript scraps loft skip content sea...\n",
       "babygirl                  babygirl transcript scraps loft skip content s...\n",
       "den-of-thieves-2-pantera  den thieves transcript scraps loft skip conten...\n",
       "moana-2                   moana scraps loft skip content search movies m...\n",
       "sonic-the-hedgehog-3      sonic hedgehog transcript scraps loft skip con...\n",
       "star-trek-section-31      star trek section transcript scraps loft skip ..."
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the nouns function to the transcripts to filter only on nouns\n",
    "data_nouns_adj = pd.DataFrame(data_clean.transcript.apply(nouns_adj))\n",
    "data_nouns_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "lplmy8TakerK"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abandons</th>\n",
       "      <th>abidjan</th>\n",
       "      <th>abilities</th>\n",
       "      <th>absorbs</th>\n",
       "      <th>abuse</th>\n",
       "      <th>accent</th>\n",
       "      <th>access</th>\n",
       "      <th>accident</th>\n",
       "      <th>account</th>\n",
       "      <th>accountability</th>\n",
       "      <th>...</th>\n",
       "      <th>zamba</th>\n",
       "      <th>zap</th>\n",
       "      <th>zapper</th>\n",
       "      <th>zeph</th>\n",
       "      <th>zephs</th>\n",
       "      <th>zilch</th>\n",
       "      <th>zocalo</th>\n",
       "      <th>zone</th>\n",
       "      <th>zones</th>\n",
       "      <th>zoom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>all-about-my-mother-1999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>babygirl</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>den-of-thieves-2-pantera</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moana-2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sonic-the-hedgehog-3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>star-trek-section-31</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows Ã— 3818 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          abandons  abidjan  abilities  absorbs  abuse  \\\n",
       "all-about-my-mother-1999         0        0          0        0      0   \n",
       "babygirl                         0        0          0        0      0   \n",
       "den-of-thieves-2-pantera         0        1          0        0      0   \n",
       "moana-2                          0        0          0        0      0   \n",
       "sonic-the-hedgehog-3             3        0          1        1      1   \n",
       "star-trek-section-31             0        0          0        0      0   \n",
       "\n",
       "                          accent  access  accident  account  accountability  \\\n",
       "all-about-my-mother-1999       0       0         2        0               0   \n",
       "babygirl                       0       0         0        0               1   \n",
       "den-of-thieves-2-pantera       0       4         0        1               0   \n",
       "moana-2                        0       0         0        0               0   \n",
       "sonic-the-hedgehog-3           0       1         1        0               0   \n",
       "star-trek-section-31           1       0         0        0               0   \n",
       "\n",
       "                          ...  zamba  zap  zapper  zeph  zephs  zilch  zocalo  \\\n",
       "all-about-my-mother-1999  ...      0    0       0     0      0      0       0   \n",
       "babygirl                  ...      0    0       0     0      0      0       0   \n",
       "den-of-thieves-2-pantera  ...      3    0       0     0      0      0       1   \n",
       "moana-2                   ...      0    0       0     0      0      0       0   \n",
       "sonic-the-hedgehog-3      ...      0    1       1     0      0      1       0   \n",
       "star-trek-section-31      ...      0    0       0    30      9      0       0   \n",
       "\n",
       "                          zone  zones  zoom  \n",
       "all-about-my-mother-1999     0      0     0  \n",
       "babygirl                     0      0     0  \n",
       "den-of-thieves-2-pantera     0      2     1  \n",
       "moana-2                      0      0     0  \n",
       "sonic-the-hedgehog-3         1      0     0  \n",
       "star-trek-section-31         0      0     0  \n",
       "\n",
       "[6 rows x 3818 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new document-term matrix using only nouns and adjectives, also remove common words with max_df\n",
    "cvna = CountVectorizer(stop_words=list(stop_words), max_df=.8)\n",
    "data_cvna = cvna.fit_transform(data_nouns_adj.transcript)\n",
    "data_dtmna = pd.DataFrame(data_cvna.toarray(), columns=cvna.get_feature_names_out())\n",
    "data_dtmna.index = data_nouns_adj.index\n",
    "data_dtmna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "HyisnxH_kerK"
   },
   "outputs": [],
   "source": [
    "# Create the gensim corpus\n",
    "corpusna = matutils.Sparse2Corpus(scipy.sparse.csr_matrix(data_dtmna.transpose()))\n",
    "\n",
    "# Create the vocabulary dictionary\n",
    "id2wordna = dict((v, k) for k, v in cvna.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.007*\"moana\" + 0.007*\"english\" + 0.006*\"sonic\" + 0.005*\"french\" + 0.004*\"maui\" + 0.004*\"fuck\" + 0.004*\"chatter\" + 0.004*\"whoa\" + 0.003*\"shadow\" + 0.003*\"um\"')]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's start with 1 topic\n",
    "ldana = models.LdaModel(corpus=corpusna, num_topics=1, id2word=id2wordna, passes=10)\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "8h6CSJsWkerK"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.013*\"english\" + 0.009*\"french\" + 0.009*\"fuck\" + 0.008*\"chatter\" + 0.005*\"serbian\" + 0.005*\"indistinct\" + 0.004*\"romy\" + 0.004*\"jovanna\" + 0.004*\"um\" + 0.004*\"car\"'),\n",
       " (1,\n",
       "  '0.013*\"moana\" + 0.010*\"sonic\" + 0.008*\"maui\" + 0.006*\"whoa\" + 0.006*\"shadow\" + 0.005*\"quasi\" + 0.005*\"garrett\" + 0.005*\"alok\" + 0.005*\"team\" + 0.004*\"zeph\"')]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's start with 2 topics\n",
    "ldana = models.LdaModel(corpus=corpusna, num_topics=2, id2word=id2wordna, passes=10)\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "kmwBF9xKkerK"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.013*\"english\" + 0.011*\"sonic\" + 0.009*\"french\" + 0.007*\"fuck\" + 0.006*\"shadow\" + 0.005*\"whoa\" + 0.005*\"quasi\" + 0.005*\"serbian\" + 0.005*\"garrett\" + 0.005*\"alok\"'),\n",
       " (1,\n",
       "  '0.016*\"moana\" + 0.011*\"maui\" + 0.006*\"chatter\" + 0.006*\"um\" + 0.005*\"romy\" + 0.005*\"moni\" + 0.005*\"loto\" + 0.004*\"huma\" + 0.004*\"mom\" + 0.004*\"island\"'),\n",
       " (2,\n",
       "  '0.001*\"moana\" + 0.001*\"maui\" + 0.001*\"english\" + 0.000*\"fuck\" + 0.000*\"quasi\" + 0.000*\"french\" + 0.000*\"playing\" + 0.000*\"ta\" + 0.000*\"whoa\" + 0.000*\"alok\"')]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try 3 topics\n",
    "ldana = models.LdaModel(corpus=corpusna, num_topics=3, id2word=id2wordna, passes=10)\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "0WGDiB18kerK"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.016*\"sonic\" + 0.009*\"shadow\" + 0.008*\"quasi\" + 0.007*\"garrett\" + 0.007*\"alok\" + 0.006*\"whoa\" + 0.006*\"team\" + 0.006*\"zeph\" + 0.005*\"ship\" + 0.005*\"fuzz\"'),\n",
       " (1,\n",
       "  '0.024*\"moana\" + 0.016*\"maui\" + 0.009*\"chatter\" + 0.009*\"um\" + 0.007*\"romy\" + 0.007*\"moni\" + 0.007*\"loto\" + 0.006*\"island\" + 0.006*\"ta\" + 0.005*\"dance\"'),\n",
       " (2,\n",
       "  '0.010*\"huma\" + 0.009*\"son\" + 0.007*\"agrado\" + 0.006*\"night\" + 0.006*\"mother\" + 0.005*\"rosa\" + 0.005*\"esteban\" + 0.005*\"manuela\" + 0.005*\"mom\" + 0.005*\"husband\"'),\n",
       " (3,\n",
       "  '0.030*\"english\" + 0.021*\"french\" + 0.017*\"fuck\" + 0.012*\"serbian\" + 0.010*\"jovanna\" + 0.008*\"indistinct\" + 0.007*\"chatter\" + 0.006*\"tense\" + 0.006*\"policeman\" + 0.006*\"suspenseful\"')]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try 4 topics\n",
    "ldana = models.LdaModel(corpus=corpusna, num_topics=4, id2word=id2wordna, passes=10)\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X4LkQRiFkerK"
   },
   "source": [
    "## Identify Topics in Each Document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0wijuoM_kerK"
   },
   "source": [
    "Out of the 9 topic models we looked at, the nouns and adjectives, 4 topic one made the most sense. So let's pull that down here and run it through some more iterations to get more fine-tuned topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "Bgr8cBHZkerK",
    "outputId": "79157256-80dd-4773-cfff-f5065be5da87"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.018*\"english\" + 0.015*\"sonic\" + 0.013*\"french\" + 0.010*\"fuck\" + 0.008*\"shadow\" + 0.007*\"serbian\" + 0.006*\"jovanna\" + 0.005*\"indistinct\" + 0.005*\"knuckles\" + 0.005*\"tom\"'),\n",
       " (1,\n",
       "  '0.024*\"moana\" + 0.016*\"maui\" + 0.009*\"chatter\" + 0.009*\"um\" + 0.007*\"romy\" + 0.007*\"moni\" + 0.007*\"loto\" + 0.006*\"ta\" + 0.006*\"island\" + 0.005*\"laughter\"'),\n",
       " (2,\n",
       "  '0.010*\"huma\" + 0.009*\"son\" + 0.007*\"agrado\" + 0.006*\"night\" + 0.006*\"mother\" + 0.005*\"manuela\" + 0.005*\"esteban\" + 0.005*\"rosa\" + 0.005*\"husband\" + 0.005*\"mom\"'),\n",
       " (3,\n",
       "  '0.014*\"quasi\" + 0.013*\"garrett\" + 0.012*\"alok\" + 0.011*\"zeph\" + 0.010*\"ship\" + 0.009*\"fuzz\" + 0.008*\"san\" + 0.008*\"godsend\" + 0.007*\"dada\" + 0.005*\"chaos\"')]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our final LDA model (for now)\n",
    "ldana = models.LdaModel(corpus=corpusna, num_topics=4, id2word=id2wordna, passes=80)\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JSqKiM4ukerL"
   },
   "source": [
    "These four topics look pretty decent. Let's settle on these for now.\n",
    "* Topic 0: moana,maui,moni,loto,ta,island,mouufetu\n",
    "* Topic 1: quasi,chatter,garrett,alok,um,zeph\n",
    "* Topic 2: huma,son,agrado,night,mother,manuela\n",
    "* Topic 3: english,sonic,french,shadow,serbian,jovanna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "D9E1IMHDkerL",
    "outputId": "13c37249-0fa2-47f7-c323-3d03d2279a48"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 'all-about-my-mother-1999'),\n",
       " (1, 'babygirl'),\n",
       " (0, 'den-of-thieves-2-pantera'),\n",
       " (1, 'moana-2'),\n",
       " (0, 'sonic-the-hedgehog-3'),\n",
       " (3, 'star-trek-section-31')]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's take a look at which topics each transcript contains\n",
    "corpus_transformed = ldana[corpusna]\n",
    "list(zip([a for [(a,b)] in corpus_transformed], data_dtmna.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "3Av1POMSkerL",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "## Additional Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "elPpbB2ckerM"
   },
   "source": [
    "1. Try further modifying the parameters of the topic models above and see if you can get better topics.\n",
    "2. Create a new topic model that includes terms from a different [part of speech](https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html) and see if you can get better topics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOUN & ADVERB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "BDENp51HkerM"
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize, pos_tag\n",
    "\n",
    "def nouns_adv(text):\n",
    "    '''Given a string of text, tokenize and pull out only nouns and adverbs.'''\n",
    "    is_noun_adv = lambda pos: pos[:2] == 'NN' or pos[:2] == 'RB'\n",
    "    tokenized = word_tokenize(text)\n",
    "    nouns_adv = [word for (word, pos) in pos_tag(tokenized) if is_noun_adv(pos)]\n",
    "    return ' '.join(nouns_adv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>all-about-my-mother-1999</th>\n",
       "      <td>mother transcript scraps content search movies...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>babygirl</th>\n",
       "      <td>babygirl transcript scraps content search movi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>den-of-thieves-2-pantera</th>\n",
       "      <td>thieves transcript scraps content search movie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moana-2</th>\n",
       "      <td>moana scraps content search movies movie movie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sonic-the-hedgehog-3</th>\n",
       "      <td>hedgehog transcript scraps content search movi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>star-trek-section-31</th>\n",
       "      <td>star trek section transcript scraps content se...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 transcript\n",
       "all-about-my-mother-1999  mother transcript scraps content search movies...\n",
       "babygirl                  babygirl transcript scraps content search movi...\n",
       "den-of-thieves-2-pantera  thieves transcript scraps content search movie...\n",
       "moana-2                   moana scraps content search movies movie movie...\n",
       "sonic-the-hedgehog-3      hedgehog transcript scraps content search movi...\n",
       "star-trek-section-31      star trek section transcript scraps content se..."
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_nouns_adv = pd.DataFrame(data_clean.transcript.apply(nouns_adv))\n",
    "data_nouns_adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abandons</th>\n",
       "      <th>abidjan</th>\n",
       "      <th>abilities</th>\n",
       "      <th>abruptly</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>absorbs</th>\n",
       "      <th>abuse</th>\n",
       "      <th>academy</th>\n",
       "      <th>access</th>\n",
       "      <th>accident</th>\n",
       "      <th>...</th>\n",
       "      <th>youngwell</th>\n",
       "      <th>youyouyou</th>\n",
       "      <th>zamba</th>\n",
       "      <th>zap</th>\n",
       "      <th>zapper</th>\n",
       "      <th>zeph</th>\n",
       "      <th>zephs</th>\n",
       "      <th>zone</th>\n",
       "      <th>zones</th>\n",
       "      <th>zoom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>all-about-my-mother-1999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>babygirl</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>den-of-thieves-2-pantera</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moana-2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sonic-the-hedgehog-3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>star-trek-section-31</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows Ã— 3109 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          abandons  abidjan  abilities  abruptly  absolutely  \\\n",
       "all-about-my-mother-1999         0        0          0         0           0   \n",
       "babygirl                         0        0          0         0           1   \n",
       "den-of-thieves-2-pantera         0        1          0         0           0   \n",
       "moana-2                          0        0          0         0           0   \n",
       "sonic-the-hedgehog-3             3        0          1         1           4   \n",
       "star-trek-section-31             0        0          0         0           2   \n",
       "\n",
       "                          absorbs  abuse  academy  access  accident  ...  \\\n",
       "all-about-my-mother-1999        0      0        0       0         2  ...   \n",
       "babygirl                        0      0        0       0         0  ...   \n",
       "den-of-thieves-2-pantera        0      0        1       4         0  ...   \n",
       "moana-2                         0      0        0       0         0  ...   \n",
       "sonic-the-hedgehog-3            1      1        0       1         1  ...   \n",
       "star-trek-section-31            0      0        0       0         0  ...   \n",
       "\n",
       "                          youngwell  youyouyou  zamba  zap  zapper  zeph  \\\n",
       "all-about-my-mother-1999          1          0      0    0       0     0   \n",
       "babygirl                          0          0      0    0       0     0   \n",
       "den-of-thieves-2-pantera          0          0      3    0       0     0   \n",
       "moana-2                           0          0      0    0       0     0   \n",
       "sonic-the-hedgehog-3              0          0      0    1       1     0   \n",
       "star-trek-section-31              0          1      0    0       0    26   \n",
       "\n",
       "                          zephs  zone  zones  zoom  \n",
       "all-about-my-mother-1999      0     0      0     0  \n",
       "babygirl                      0     0      0     0  \n",
       "den-of-thieves-2-pantera      0     0      2     1  \n",
       "moana-2                       0     0      0     0  \n",
       "sonic-the-hedgehog-3          0     1      0     0  \n",
       "star-trek-section-31          7     0      0     0  \n",
       "\n",
       "[6 rows x 3109 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvna = CountVectorizer(stop_words=list(stop_words), max_df=.8)\n",
    "data_cvna = cvna.fit_transform(data_nouns_adv.transcript)  # use data_nouns_adv now\n",
    "data_dtmna = pd.DataFrame(data_cvna.toarray(), columns=cvna.get_feature_names_out())\n",
    "data_dtmna.index = data_nouns_adv.index\n",
    "data_dtmna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the gensim corpus from the noun+adverb DTM\n",
    "corpus_na_adv = matutils.Sparse2Corpus(scipy.sparse.csr_matrix(data_dtmna.transpose()))\n",
    "\n",
    "# Create the vocabulary dictionary for gensim\n",
    "id2word_na_adv = dict((v, k) for k, v in cvna.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.007*\"moana\" + 0.007*\"english\" + 0.006*\"sonic\" + 0.005*\"french\" + 0.004*\"chatter\" + 0.004*\"fuck\" + 0.004*\"maui\" + 0.004*\"whoa\" + 0.003*\"shadow\" + 0.003*\"um\"')]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's start with 1 topic\n",
    "ldana = models.LdaModel(corpus=corpusna, num_topics=1, id2word=id2wordna, passes=10)\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.015*\"moana\" + 0.010*\"maui\" + 0.005*\"chatter\" + 0.005*\"um\" + 0.005*\"romy\" + 0.005*\"moni\" + 0.004*\"loto\" + 0.004*\"huma\" + 0.004*\"ta\" + 0.004*\"island\"'),\n",
       " (1,\n",
       "  '0.012*\"english\" + 0.010*\"sonic\" + 0.009*\"french\" + 0.006*\"fuck\" + 0.005*\"shadow\" + 0.005*\"whoa\" + 0.005*\"quasi\" + 0.005*\"serbian\" + 0.005*\"garrett\" + 0.004*\"alok\"')]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's start with 2 topic\n",
    "ldana = models.LdaModel(corpus=corpusna, num_topics=2, id2word=id2wordna, passes=10)\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.016*\"moana\" + 0.014*\"sonic\" + 0.011*\"maui\" + 0.007*\"shadow\" + 0.006*\"whoa\" + 0.005*\"moni\" + 0.005*\"loto\" + 0.005*\"knuckles\" + 0.005*\"tom\" + 0.004*\"ta\"'),\n",
       " (1,\n",
       "  '0.011*\"english\" + 0.008*\"french\" + 0.007*\"fuck\" + 0.007*\"chatter\" + 0.005*\"quasi\" + 0.004*\"garrett\" + 0.004*\"serbian\" + 0.004*\"indistinct\" + 0.004*\"alok\" + 0.004*\"romy\"')]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 50 passes\n",
    "ldana = models.LdaModel(corpus=corpusna, num_topics=2, id2word=id2wordna, passes=50)\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.016*\"english\" + 0.012*\"french\" + 0.009*\"fuck\" + 0.007*\"quasi\" + 0.006*\"serbian\" + 0.006*\"garrett\" + 0.006*\"alok\" + 0.005*\"jovanna\" + 0.005*\"zeph\" + 0.005*\"ship\"'),\n",
       " (1,\n",
       "  '0.011*\"moana\" + 0.009*\"sonic\" + 0.007*\"maui\" + 0.005*\"shadow\" + 0.005*\"um\" + 0.005*\"chatter\" + 0.004*\"whoa\" + 0.004*\"romy\" + 0.003*\"moni\" + 0.003*\"loto\"')]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 80 passes\n",
    "ldana = models.LdaModel(corpus=corpusna, num_topics=2, id2word=id2wordna, passes=80)\n",
    "ldana.print_topics()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
